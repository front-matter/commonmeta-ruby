---
http_interactions:
- request:
    method: get
    uri: https://rogue-scholar.org/api/blogs/tyfqw20
    body:
      encoding: UTF-8
      string: ''
    headers:
      Connection:
      - close
      Host:
      - rogue-scholar.org
      User-Agent:
      - http.rb/5.1.1
  response:
    status:
      code: 200
      message: OK
    headers:
      Age:
      - '0'
      Cache-Control:
      - public, max-age=0, must-revalidate
      Content-Length:
      - '88356'
      Content-Type:
      - application/json; charset=utf-8
      Date:
      - Sun, 18 Jun 2023 06:01:20 GMT
      Etag:
      - '"xxw11pz9vb1w14"'
      Server:
      - Vercel
      Strict-Transport-Security:
      - max-age=63072000
      X-Matched-Path:
      - "/api/blogs/[slug]"
      X-Vercel-Cache:
      - MISS
      X-Vercel-Id:
      - fra1::iad1::fqtvx-1687068074466-8dd4935835aa
      Connection:
      - close
    body:
      encoding: UTF-8
      string: '{"id":"tyfqw20","title":"iPhylo","description":"Rants, raves (and occasionally
        considered opinions) on phyloinformatics, taxonomy, and biodiversity informatics.  For
        more ranty and less considered opinions, see my <a href=\"https://twitter.com/rdmpage\">Twitter
        feed</a>.<br>ISSN 2051-8188. Written content on this site is licensed under
        a <a href=\"https://creativecommons.org/licenses/by/4.0/\">Creative Commons
        Attribution 4.0 International license</a>.","language":"en","favicon":null,"feed_url":"https://iphylo.blogspot.com/feeds/posts/default","feed_format":"application/atom+xml","home_page_url":"https://iphylo.blogspot.com/","indexed_at":"2023-02-06","modified_at":"2023-05-31T17:26:00+00:00","license":"https://creativecommons.org/licenses/by/4.0/legalcode","generator":"Blogger
        7.00","category":"Natural Sciences","backlog":true,"prefix":"10.59350","items":[{"id":"https://doi.org/10.59350/en7e9-5s882","uuid":"20b9d31e-513f-496b-b399-4215306e1588","url":"https://iphylo.blogspot.com/2022/04/obsidian-markdown-and-taxonomic-trees.html","title":"Obsidian,
        markdown, and taxonomic trees","summary":"Returning to the subject of personal
        knowledge graphs Kyle Scheer has an interesting repository of Markdown files
        that describe academic disciplines at https://github.com/kyletscheer/academic-disciplines
        (see his blog post for more background). If you add these files to Obsidian
        you get a nice visualisation of a taxonomy of academic disciplines. The applications
        of this to biological taxonomy seem obvious, especially as a tool like Obsidian
        enables all sorts of interesting links to be added...","date_published":"2022-04-07T21:07:00Z","date_modified":"2022-04-07T21:15:34Z","date_indexed":"1909-06-16T09:41:45+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<p>Returning to the subject of <a href=\"https://iphylo.blogspot.com/2020/08/personal-knowledge-graphs-obsidian-roam.html\">personal
        knowledge graphs</a> Kyle Scheer has an interesting repository of Markdown
        files that describe academic disciplines at <a href=\"https://github.com/kyletscheer/academic-disciplines\">https://github.com/kyletscheer/academic-disciplines</a>
        (see <a href=\"https://kyletscheer.medium.com/on-creating-a-tree-of-knowledge-f099c1028bf6\">his
        blog post</a> for more background).</p>\n\n<p>If you add these files to <a
        href=\"https://obsidian.md/\">Obsidian</a> you get a nice visualisation of
        a taxonomy of academic disciplines. The applications of this to biological
        taxonomy seem obvious, especially as a tool like Obsidian enables all sorts
        of interesting links to be added (e.g., we could add links to the taxonomic
        research behind each node in the taxonomic tree, the people doing that research,
        etc. - although that would mean we''d no longer have a simple tree).</p>\n\n<p>The
        more I look at these sort of simple Markdown-based tools the more I wonder
        whether we could make more use of them to create simple but persistent databases.
        Text files seem the most stable, long-lived digital format around, maybe this
        would be a way to minimise the inevitable obsolescence of database and server
        software. Time for some experiments I feel... can we take a taxonomic group,
        such as mammals, and create a richly connected database purely in Markdown?</p>\n\n<div
        class=\"separator\" style=\"clear: both; text-align: center;\"><iframe allowfullscreen=''allowfullscreen''
        webkitallowfullscreen=''webkitallowfullscreen'' mozallowfullscreen=''mozallowfullscreen''
        width=''400'' height=''322'' src=''https://www.blogger.com/video.g?token=AD6v5dxZtweOTJTdg6aqvICq_tKF0la1QZuDAEpwPPCVQKtG5vjB-DzuQv-ApL8JnpyZ1FffYtWo6ymizNQ''
        class=''b-hbp-video b-uploaded'' frameborder=''0''></iframe></div>","tags":["markdown","obsidian"],"language":"en","references":[]},{"id":"https://doi.org/10.59350/m48f7-c2128","uuid":"8aea47e4-f227-45f4-b37b-0454a8a7a3ff","url":"https://iphylo.blogspot.com/2023/04/chatgpt-semantic-search-and-knowledge.html","title":"ChatGPT,
        semantic search, and knowledge graphs","summary":"One thing about ChatGPT
        is it has opened my eyes to some concepts I was dimly aware of but am only
        now beginning to fully appreciate. ChatGPT enables you ask it questions, but
        the answers depend on what ChatGPT “knows”. As several people have noted,
        what would be even better is to be able to run ChatGPT on your own content.
        Indeed,  ChatGPT itself now supports this using plugins. Paul Graham GPT However,
        it’s still useful to see how to add ChatGPT functionality to your own content
        from...","date_published":"2023-04-03T15:30:00Z","date_modified":"2023-04-03T15:32:04Z","date_indexed":"1909-06-16T09:02:34+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<p>One thing about ChatGPT is it has
        opened my eyes to some concepts I was dimly aware of but am only now beginning
        to fully appreciate. ChatGPT enables you ask it questions, but the answers
        depend on what ChatGPT “knows”. As several people have noted, what would be
        even better is to be able to run ChatGPT on your own content. Indeed,  ChatGPT
        itself now supports this using <a href=\"https://openai.com/blog/chatgpt-plugins\">plugins</a>.</p>\n<h4
        id=\"paul-graham-gpt\">Paul Graham GPT</h4>\n<p>However, it’s still useful
        to see how to add ChatGPT functionality to your own content from scratch.
        A nice example of this is <a href=\"https://paul-graham-gpt.vercel.app/\">Paul
        Graham GPT</a> by <a href=\"https://twitter.com/mckaywrigley\">Mckay Wrigley</a>.
        Mckay Wrigley took essays by Paul Graham (a well known venture capitalist)
        and built a question and answer tool very like ChatGPT.</p>\n<iframe width=\"560\"
        height=\"315\" src=\"https://www.youtube.com/embed/ii1jcLg-eIQ\" title=\"YouTube
        video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write;
        encrypted-media; gyroscope; picture-in-picture; web-share\" allowfullscreen></iframe>\n<p>Because
        you can send a block of text to ChatGPT (as part of the prompt) you can get
        ChatGPT to summarise or transform that information, or answer questions based
        on that information. But there is a limit to how much information you can
        pack into a prompt. You can’t put all of Paul Graham’s essays into a prompt
        for example. So a solution is to do some preprocessing. For example, given
        a question such as “How do I start a startup?” we could first find the essays
        that are most relevant to this question, then use them to create a prompt
        for ChatGPT. A quick and dirty way to do this is simply do a text search over
        the essays and take the top hits. But we aren’t searching for words, we are
        searching for answers to a question. The essay with the best answer might
        not include the phrase “How do I start a startup?”.</p>\n<h4 id=\"semantic-search\">Semantic
        search</h4>\n<p>Enter <a href=\"https://en.wikipedia.org/wiki/Semantic_search\">Semantic
        search</a>. The key concept behind semantic search is that we are looking
        for documents with similar meaning, not just similarity of text. One approach
        to this is to represent documents by “embeddings”, that is, a vector of numbers
        that encapsulate features of the document. Documents with similar vectors
        are potentially related. In semantic search we take the query (e.g., “How
        do I start a startup?”), compute its embedding, then search among the documents
        for those with similar embeddings.</p>\n<p>To create Paul Graham GPT Mckay
        Wrigley did the following. First he sent each essay to the OpenAI API underlying
        ChatGPT, and in return he got the embedding for that essay (a vector of 1536
        numbers). Each embedding was stored in a database (Mckay uses Postgres with
        <a href=\"https://github.com/pgvector/pgvector\">pgvector</a>). When a user
        enters a query such as “How do I start a startup?” that query is also sent
        to the OpenAI API to retrieve its embedding vector. Then we query the database
        of embeddings for Paul Graham’s essays and take the top five hits. These hits
        are, one hopes, the most likely to contain relevant answers. The original
        question and the most similar essays are then bundled up and sent to ChatGPT
        which then synthesises an answer. See his <a href=\"https://github.com/mckaywrigley/paul-graham-gpt\">GitHub
        repo</a> for more details. Note that we are still using ChatGPT, but on a
        set of documents it doesn’t already have.</p>\n<h4 id=\"knowledge-graphs\">Knowledge
        graphs</h4>\n<p>I’m a fan of knowledge graphs, but they are not terribly easy
        to use. For example, I built a knowledge graph of Australian animals <a href=\"https://ozymandias-demo.herokuapp.com\">Ozymandias</a>
        that contains a wealth of information on taxa, publications, and people, wrapped
        up in a web site. If you want to learn more you need to figure out how to
        write queries in SPARQL, which is not fun. Maybe we could use ChatGPT to write
        the SPARQL queries for us, but it would be much more fun to be simply ask
        natural language queries (e.g., “who are the experts on Australian ants?”).
        I made some naïve notes on these ideas <a href=\"https://iphylo.blogspot.com/2015/09/possible-project-natural-language.html\">Possible
        project: natural language queries, or answering “how many species are there?”</a>
        and <a href=\"https://iphylo.blogspot.com/2019/05/ozymandias-meets-wikipedia-with-notes.html\">Ozymandias
        meets Wikipedia, with notes on natural language generation</a>.</p>\n<p>Of
        course, this is a well known problem. Tools such as <a href=\"http://rdf2vec.org\">RDF2vec</a>
        can take RDF from a knowledge graph and create embeddings which could in tern
        be used to support semantic search. But it seems to me that we could simply
        this process a bit by making use of ChatGPT.</p>\n<p>Firstly we would generate
        natural language statements from the knowledge graph (e.g., “species x belongs
        to genus y and was described in z”, “this paper on ants was authored by x”,
        etc.) that cover the basic questions we expect people to ask. We then get
        embeddings for these (e.g., using OpenAI). We then have an interface where
        people can ask a question (“is species x a valid species?”, “who has published
        on ants”, etc.), we get the embedding for that question, retrieve natural
        language statements that the closest in embedding “space”, package everything
        up and ask ChatGPT to summarise the answer.</p>\n<p>The trick, of course,
        is to figure out how t generate natural language statements from the knowledge
        graph (which amounts to deciding what paths to traverse in the knowledge graph,
        and how to write those paths is something approximating English). We also
        want to know something about the sorts of questions people are likely to ask
        so that we have a reasonable chance of having the answers (for example, are
        people going to ask about individual species, or questions about summary statistics
        such as numbers of species in  a genus, etc.).</p>\n<p>What makes this attractive
        is that it seems a straightforward way to go from a largely academic exercise
        (build a knowledge graph) to something potentially useful (a question and
        answer machine). Imagine if something like the defunct BBC wildlife site (see
        <a href=\"https://iphylo.blogspot.com/2017/12/blue-planet-ii-bbc-and-semantic-web.html\">Blue
        Planet II, the BBC, and the Semantic Web: a tale of lessons forgotten and
        opportunities lost</a>) revived <a href=\"https://aspiring-look.glitch.me\">here</a>
        had a question and answer interface where we could ask questions rather than
        passively browse.</p>\n<h4 id=\"summary\">Summary</h4>\n<p>I have so much
        more to learn, and need to think about ways to incorporate semantic search
        and ChatGPT-like tools into knowledge graphs.</p>\n<blockquote>\n<p>Written
        with <a href=\"https://stackedit.io/\">StackEdit</a>.</p>\n</blockquote>","tags":[],"language":"en","references":[]},{"id":"https://doi.org/10.59350/zc4qc-77616","uuid":"30c78d9d-2e50-49db-9f4f-b3baa060387b","url":"https://iphylo.blogspot.com/2022/09/does-anyone-cite-taxonomic-treatments.html","title":"Does
        anyone cite taxonomic treatments?","summary":"Taxonomic treatments have come
        up in various discussions I''m involved in, and I''m curious as to whether
        they are actually being used, in particular, whether they are actually being
        cited. Consider the following quote: The taxa are described in taxonomic treatments,
        well defined sections of scientific publications (Catapano 2019). They include
        a nomenclatural section and one or more sections including descriptions, material
        citations referring to studied specimens, or notes ecology and...","date_published":"2022-09-01T16:49:00Z","date_modified":"2022-09-01T16:49:51Z","date_indexed":"1909-06-16T09:31:50+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<div class=\"separator\" style=\"clear:
        both;\"><a href=\"https://zenodo.org/record/5731100/thumb100\" style=\"display:
        block; padding: 1em 0; text-align: center; clear: right; float: right;\"><img
        alt=\"\" border=\"0\" height=\"128\" data-original-height=\"106\" data-original-width=\"100\"
        src=\"https://zenodo.org/record/5731100/thumb250\"/></a></div>\nTaxonomic
        treatments have come up in various discussions I''m involved in, and I''m
        curious as to whether they are actually being used, in particular, whether
        they are actually being cited. Consider the following quote:\n\n<blockquote>\nThe
        taxa are described in taxonomic treatments, well defined sections of scientific
        publications (Catapano 2019). They include a nomenclatural section and one
        or more sections including descriptions, material citations referring to studied
        specimens, or notes ecology and behavior. In case the treatment does not describe
        a new discovered taxon, previous treatments are cited in the form of treatment
        citations. This citation can refer to a previous treatment and add additional
        data, or it can be a statement synonymizing the taxon with another taxon.
        This allows building a citation network, and ultimately is a constituent part
        of the catalogue of life. - Taxonomic Treatments as Open FAIR Digital Objects
        <a href=\"https://doi.org/10.3897/rio.8.e93709\">https://doi.org/10.3897/rio.8.e93709</a>\n</blockquote>\n\n<p>\n
        \"Traditional\" academic citation is from article to article. For example,
        consider these two papers:\n\n<blockquote>\nLi Y, Li S, Lin Y (2021) Taxonomic
        study on fourteen symphytognathid species from Asia (Araneae, Symphytognathidae).
        ZooKeys 1072: 1-47. https://doi.org/10.3897/zookeys.1072.67935\n</blockquote>\n\n<blockquote>\nMiller
        J, Griswold C, Yin C (2009) The symphytognathoid spiders of the Gaoligongshan,
        Yunnan, China (Araneae: Araneoidea): Systematics and diversity of micro-orbweavers.
        ZooKeys 11: 9-195. https://doi.org/10.3897/zookeys.11.160\n</blockquote>\n</p>\n\n<p>Li
        et al. 2021 cites Miller et al. 2009 (although Pensoft seems to have broken
        the citation such that it does appear correctly either on their web page or
        in CrossRef).</p>\n\n<p>So, we have this link: [article]10.3897/zookeys.1072.67935
        --cites--> [article]10.3897/zookeys.11.160. One article cites another.</p>\n\n<p>In
        their 2021 paper Li et al. discuss <i>Patu jidanweishi</i> Miller, Griswold
        & Yin, 2009:\n\n<div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgPavMHXqQNX1ls_zXo9kIcMLHPxc7ZpV9NCSof5wLumrg3ovPoi6nYKzZsINuqFtYoEvW1QrerePD-MEf2DJaYUXlT37d81x3L6ILls7u229rg0_Nc0uUmgW-ICzr6MI_QCZfgQbYGTxuofu-fuPVoygbCnm3vQVYOhLDLtp1EtQ9jRZHDvw/s1040/Screenshot%202022-09-01%20at%2017.12.27.png\"
        style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"\"
        border=\"0\" width=\"400\" data-original-height=\"314\" data-original-width=\"1040\"
        src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEgPavMHXqQNX1ls_zXo9kIcMLHPxc7ZpV9NCSof5wLumrg3ovPoi6nYKzZsINuqFtYoEvW1QrerePD-MEf2DJaYUXlT37d81x3L6ILls7u229rg0_Nc0uUmgW-ICzr6MI_QCZfgQbYGTxuofu-fuPVoygbCnm3vQVYOhLDLtp1EtQ9jRZHDvw/s400/Screenshot%202022-09-01%20at%2017.12.27.png\"/></a></div>\n\n<p>There
        is a treatment for the original description of <i>Patu jidanweishi</i> at
        <a href=\"https://doi.org/10.5281/zenodo.3792232\">https://doi.org/10.5281/zenodo.3792232</a>,
        which was created by Plazi with a time stamp \"2020-05-06T04:59:53.278684+00:00\".
        The original publication date was 2009, the treatments are being added retrospectively.</p>\n\n<p>In
        an ideal world my expectation would be that Li et al. 2021 would have cited
        the treatment, instead of just providing the text string \"Patu jidanweishi
        Miller, Griswold & Yin, 2009: 64, figs 65A–E, 66A, B, 67A–D, 68A–F, 69A–F,
        70A–F and 71A–F (♂♀).\" Isn''t the expectation under the treatment model that
        we would have seen this relationship:</p>\n\n<p>[article]10.3897/zookeys.1072.67935
        --cites--> [treatment]https://doi.org/10.5281/zenodo.3792232</p>\n\n<p>Furthermore,
        if it is the case that \"[i]n case the treatment does not describe a new discovered
        taxon, previous treatments are cited in the form of treatment citations\"
        then we should also see a citation between treatments, in other words Li et
        al.''s 2021 treatment of <i>Patu jidanweishi</i> (which doesn''t seem to have
        a DOI but is available on Plazi'' web site as <a href=\"https://tb.plazi.org/GgServer/html/1CD9FEC313A35240938EC58ABB858E74\">https://tb.plazi.org/GgServer/html/1CD9FEC313A35240938EC58ABB858E74</a>)
        should also cite the original treatment? It doesn''t - but it does cite the
        Miller et al. paper.</p>\n\n<p>So in this example we don''t see articles citing
        treatments, nor do we see treatments citing treatments. Playing Devil''s advocate,
        why then do we have treatments? Does''t the lack of citations suggest that
        - despite some taxonomists saying this is the unit that matters - they actually
        don''t. If we pay attention to what people do rather than what they say they
        do, they cite articles.</p>\n\n<p>Now, there are all sorts of reasons why
        we don''t see [article] -> [treatment] citations, or [treatment] -> [treatment]
        citations. Treatments are being added after the fact by Plazi, not by the
        authors of the original work. And in many cases the treatments that could
        be cited haven''t appeared until after that potentially citing work was published.
        In the example above the Miller et al. paper dates from 2009, but the treatment
        extracted only went online in 2020. And while there is a long standing culture
        of citing publications (ideally using DOIs) there isn''t an equivalent culture
        of citing treatments (beyond the simple text strings).</p>\n\n<p>Obviously
        this is but one example. I''d need to do some exploration of the citation
        graph to get a better sense of citations patterns, perhaps using <a href=\"https://www.crossref.org/documentation/event-data/\">CrossRef''s
        event data</a>. But my sense is that taxonomists don''t cite treatments.</p>\n\n<p>I''m
        guessing Plazi would respond by saying treatments are cited, for example (indirectly)
        in GBIF downloads. This is true, although arguably people aren''t citing the
        treatment, they''re citing specimen data in those treatments, and that specimen
        data could be extracted at the level of articles rather than treatments. In
        other words, it''s not the treatments themselves that people are citing.</p>\n\n<p>To
        be clear, I think there is value in being able to identify those \"well defined
        sections\" of a publication that deal with a given taxon (i.e., treatments),
        but it''s not clear to me that these are actually the citable units people
        might hope them to be. Likewise, journals such as <i>ZooKeys</i> have DOIs
        for individual figures. Does anyone actually cite those?</p>","tags":[],"language":"en","references":[]},{"id":"https://doi.org/10.59350/pmhat-5ky65","uuid":"5891c709-d139-440f-bacb-06244424587a","url":"https://iphylo.blogspot.com/2021/10/problems-with-plazi-parsing-how.html","title":"Problems
        with Plazi parsing: how reliable are automated methods for extracting specimens
        from the literature?","summary":"The Plazi project has become one of the major
        contributors to GBIF with some 36,000 datasets yielding some 500,000 occurrences
        (see Plazi''s GBIF page for details). These occurrences are extracted from
        taxonomic publication using automated methods. New data is published almost
        daily (see latest treatments). The map below shows the geographic distribution
        of material citations provided to GBIF by Plazi, which gives you a sense of
        the size of the dataset. By any metric Plazi represents a...","date_published":"2021-10-25T11:10:00Z","date_modified":"2021-10-28T16:08:18Z","date_indexed":"1970-01-01T00:00:00+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<div class=\"separator\" style=\"clear:
        both;\"><a href=\"https://1.bp.blogspot.com/-oiqSkA53FI4/YXaRAUpRgFI/AAAAAAAAgzY/PbPEOh_VlhIE0aaqqhVQPLAOE5pRULwJACLcBGAsYHQ/s240/Rf7UoXTw_400x400.jpg\"
        style=\"display: block; padding: 1em 0; text-align: center; clear: right;
        float: right;\"><img alt=\"\" border=\"0\" width=\"128\" data-original-height=\"240\"
        data-original-width=\"240\" src=\"https://1.bp.blogspot.com/-oiqSkA53FI4/YXaRAUpRgFI/AAAAAAAAgzY/PbPEOh_VlhIE0aaqqhVQPLAOE5pRULwJACLcBGAsYHQ/s200/Rf7UoXTw_400x400.jpg\"/></a></div><p>The
        <a href=\"http://plazi.org\">Plazi</a> project has become one of the major
        contributors to GBIF with some 36,000 datasets yielding some 500,000 occurrences
        (see <a href=\"https://www.gbif.org/publisher/7ce8aef0-9e92-11dc-8738-b8a03c50a862\">Plazi''s
        GBIF page</a> for details). These occurrences are extracted from taxonomic
        publication using automated methods. New data is published almost daily (see
        <a href=\"https://tb.plazi.org/GgServer/static/newToday.html\">latest treatments</a>).
        The map below shows the geographic distribution of material citations provided
        to GBIF by Plazi, which gives you a sense of the size of the dataset.</p>\n\n<div
        class=\"separator\" style=\"clear: both;\"><a href=\"https://1.bp.blogspot.com/-DCJ4HR8eej8/YXaRQnz22bI/AAAAAAAAgz4/AgRcree6jVgjtQL2ch7IXgtb_Xtx7fkngCPcBGAYYCw/s1030/Screenshot%2B2021-10-24%2Bat%2B20.43.23.png\"
        style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"\"
        border=\"0\" width=\"400\" data-original-height=\"514\" data-original-width=\"1030\"
        src=\"https://1.bp.blogspot.com/-DCJ4HR8eej8/YXaRQnz22bI/AAAAAAAAgz4/AgRcree6jVgjtQL2ch7IXgtb_Xtx7fkngCPcBGAYYCw/s400/Screenshot%2B2021-10-24%2Bat%2B20.43.23.png\"/></a></div>\n\n<p>By
        any metric Plazi represents a considerable achievement. But often when I browse
        individual records on Plazi I find records that seem clearly incorrect. Text
        mining the literature is a challenging problem, but at the moment Plazi seems
        something of a \"black box\". PDFs go in, the content is mined, and data comes
        up to be displayed on the Plazi web site and uploaded to GBIF. Nowhere does
        there seem to be an evaluation of how accurate this text mining actually is.
        Anecdotally it seems to work well in some cases, but in others it produces
        what can only be described as bogus records.</p>\n\n<h2>Finding errors</h2>\n\n<p>A
        treatment in Plazi is a block of text (and sometimes illustrations) that refers
        to a single taxon. Often that text will include a description of the taxon,
        and list one or more specimens that have been examined. These lists of specimens
        (\"material citations\") are one of the key bits of information that Plaza
        extracts from a treatment as these citations get fed into GBIF as occurrences.</p>\n\n<p>To
        help explore treatments I''ve constructed a simple web site that takes the
        Plazi identifier for a treatment and displays that treatment with the material
        citations highlighted. For example, for the Plazi treatment <a href=\"https://tb.plazi.org/GgServer/html/03B5A943FFBB6F02FE27EC94FABEEAE7\">03B5A943FFBB6F02FE27EC94FABEEAE7</a>
        you can view the marked up version at <a href=\"https://plazi-tester.herokuapp.com/?uri=622F7788-F0A4-449D-814A-5B49CD20B228\">https://plazi-tester.herokuapp.com/?uri=622F7788-F0A4-449D-814A-5B49CD20B228</a>.
        Below is an example of a material citation with its component parts tagged:</p>\n\n<div
        class=\"separator\" style=\"clear: both;\"><a href=\"https://1.bp.blogspot.com/-NIGuo9BggdA/YXaRQQrv0QI/AAAAAAAAgz4/SZDcA1jZSN47JMRTWDwSMRpHUShrCeOdgCPcBGAYYCw/s693/Screenshot%2B2021-10-24%2Bat%2B20.59.56.png\"
        style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"\"
        border=\"0\" width=\"400\" data-original-height=\"94\" data-original-width=\"693\"
        src=\"https://1.bp.blogspot.com/-NIGuo9BggdA/YXaRQQrv0QI/AAAAAAAAgz4/SZDcA1jZSN47JMRTWDwSMRpHUShrCeOdgCPcBGAYYCw/s400/Screenshot%2B2021-10-24%2Bat%2B20.59.56.png\"/></a></div>\n\n<p>This
        is an example where Plazi has successfully parsed the specimen. But I keep
        coming across cases where specimens have not been parsed correctly, resulting
        in issues such as single specimens being split into multiple records (e.g.,  <a
        href=\"https://plazi-tester.herokuapp.com/?uri=5244B05EFFC8E20F7BC32056C178F496\">https://plazi-tester.herokuapp.com/?uri=5244B05EFFC8E20F7BC32056C178F496</a>),
        geographical coordinates being misinterpreted (e.g., <a href=\"https://plazi-tester.herokuapp.com/?uri=0D228E6AFFC2FFEFFF4DE8118C4EE6B9\">https://plazi-tester.herokuapp.com/?uri=0D228E6AFFC2FFEFFF4DE8118C4EE6B9</a>),
        or collector''s initials being confused with codes for natural history collections
        (e.g., <a href=\"https://plazi-tester.herokuapp.com/?uri=252C87918B362C05FF20F8C5BFCB3D4E\">https://plazi-tester.herokuapp.com/?uri=252C87918B362C05FF20F8C5BFCB3D4E</a>).</p>\n\n<p>Parsing
        specimens is a hard problem so it''s not unexpected to find errors. But they
        do seem common enough to be easily found, which raises the question of just
        what percentage of these  material citations are correct? How much of the
        data Plazi feeds to GBIF is correct? How would we know?</p>\n\n<h2>Systemic
        problems</h2>\n\n<p>Some of the errors I''ve found concern the interpretation
        of the parsed data. For example, it is striking that despite including marine
        taxa <b>no</b> Plazi record has a value for depth below sea level (see <a
        href=\"https://www.gbif.org/occurrence/map?depth=0,9999&publishing_org=7ce8aef0-9e92-11dc-8738-b8a03c50a862&advanced=1\">GBIF
        search on depth range 0-9999 for Plazi</a>). But <a href=\"https://www.gbif.org/occurrence/map?elevation=0,9999&publishing_org=7ce8aef0-9e92-11dc-8738-b8a03c50a862&advanced=1\">many
        records do have an elevation</a>, including records from marine environments.
        Any record that has a depth value is interpreted by Plazi as being elevation,
        so we have aerial crustacea and fish.</p>\n\n<h3>Map of Plazi records with
        depth 0-9999m</h3>\n<div class=\"separator\" style=\"clear: both;\"><a href=\"https://1.bp.blogspot.com/-GD4pPtPCxVc/YXaRQ9bdn1I/AAAAAAAAgz8/A9YsypSvHfwWKAjDxSdeFVUkou88LGItACPcBGAYYCw/s673/Screenshot%2B2021-10-25%2Bat%2B12.03.51.png\"
        style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"\"
        border=\"0\" width=\"400\" data-original-height=\"258\" data-original-width=\"673\"
        src=\"https://1.bp.blogspot.com/-GD4pPtPCxVc/YXaRQ9bdn1I/AAAAAAAAgz8/A9YsypSvHfwWKAjDxSdeFVUkou88LGItACPcBGAYYCw/s320/Screenshot%2B2021-10-25%2Bat%2B12.03.51.png\"/></a></div>\n\n<h3>Map
        of Plazi records with elevation 0-9999m </h3>\n<div class=\"separator\" style=\"clear:
        both;\"><a href=\"https://1.bp.blogspot.com/-BReSHtXTOkA/YXaRRKFW7dI/AAAAAAAAg0A/-FcBkMwyswIp0siWGVX3MNMANs7UkZFtwCPcBGAYYCw/s675/Screenshot%2B2021-10-25%2Bat%2B12.04.06.png\"
        style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"\"
        border=\"0\" width=\"400\" data-original-height=\"256\" data-original-width=\"675\"
        src=\"https://1.bp.blogspot.com/-BReSHtXTOkA/YXaRRKFW7dI/AAAAAAAAg0A/-FcBkMwyswIp0siWGVX3MNMANs7UkZFtwCPcBGAYYCw/s320/Screenshot%2B2021-10-25%2Bat%2B12.04.06.png\"/></a></div>\n\n<p>Anecdotally
        I''ve also noticed that Plazi seems to do well on zoological data, especially
        journals like <i>Zootaxa</i>, but it often struggles with botanical specimens.
        Botanists tend to cite specimens rather differently to zoologists (botanists
        emphasise collector numbers rather than specimen codes). Hence data quality
        in Plazi is likely to taxonomic biased.</p>\n\n<p>Plazi is <a href=\"https://github.com/plazi/community/issues\">using
        GitHub to track issues with treatments</a> so feedback on erroneous records
        is possible, but this seems inadequate to the task. There are tens of thousands
        of data sets, with more being released daily, and hundreds of thousands of
        occurrences, and relying on GitHub issues devolves the responsibility for
        error checking onto the data users. I don''t have a measure of how many records
        in Plazi have problems, but because I suspect it is a significant fraction
        because for any given day''s output I can typically find errors.</p>\n\n<h2>What
        to do?</h2>\n\n<p>Faced with a process that generates noisy data there are
        several of things we could do:</p>\n\n<ol>\n<li>Have tools to detect and flag
        errors made in generating the data.</li>\n<li>Have the data generator give
        estimates the confidence of its results.</li>\n<li>Improve the data generator.</li>\n</ol>\n\n<p>I
        think a comparison with the problem of parsing bibliographic references might
        be instructive here. There is a long history of people developing tools to
        parse references (<a href=\"https://iphylo.blogspot.com/2021/05/finding-citations-of-specimens.html\">I''ve
        even had a go</a>). State-of-the art tools such as <a href=\"https://anystyle.io\">AnyStyle</a>
        feature machine learning, and are tested against <a href=\"https://github.com/inukshuk/anystyle/blob/master/res/parser/core.xml\">human
        curated datasets</a> of tagged bibliographic records. This means we can evaluate
        the performance of a method (how well does it retrieve the same results as
        human experts?) and also improve the method by expanding the corpus of training
        data. Some of these tools can provide a measures of how confident they are
        when classifying a string as, say, a person''s name, which means we could
        flag potential issues for anyone wanting to use that record.</p>\n\n<p>We
        don''t have equivalent tools for parsing specimens in the literature, and
        hence have no easy way to quantify how good existing methods are, nor do we
        have a public corpus of material citations that we can use as training data.
        I <a href=\"https://iphylo.blogspot.com/2021/05/finding-citations-of-specimens.html\">blogged
        about this</a> a few months ago and was considering using Plazi as a source
        of marked up specimen data to use for training. However based on what I''ve
        looked at so far Plazi''s data would need to be carefully scrutinised before
        it could be used as training data.</p>\n\n<p>Going forward, I think it would
        be desirable to have a set of records that can be used to benchmark specimen
        parsers, and ideally have the parsers themselves available as web services
        so that anyone can evaluate them. Even better would be a way to contribute
        to the training data so that these tools improve over time.</p>\n\n<p>Plazi''s
        data extraction tools are mostly desktop-based, that is, you need to download
        software to use their methods. However, there are experimental web services
        available as well. I''ve created a simple wrapper around the material citation
        parser, you can try it at <a href=\"https://plazi-tester.herokuapp.com/parser.php\">https://plazi-tester.herokuapp.com/parser.php</a>.
        It takes a single material citation and returns a version with elements such
        as specimen code and collector name tagged in different colours.</p>\n\n<h2>Summary</h2>\n\n<p>Text
        mining the taxonomic literature is clearly a gold mine of data, but at the
        same time it is potentially fraught as we try and extract structured data
        from semi-structured text. Plazi has demonstrated that it is possible to extract
        a lot of data from the literature, but at the same time the quality of that
        data seems highly variable. Even minor issues in parsing text can have big
        implications for data quality (e.g., marine organisms apparently living above
        sea level). Historically in biodiversity informatics we have favoured data
        quantity over data quality. Quantity has an obvious metric, and has milestones
        we can celebrate (e.g., <a href=\"GBIF at 1 billion - what''s next?\">one
        billion specimens</a>). There aren''t really any equivalent metrics for data
        quality.</p>\n\n<p>Adding new types of data can sometimes initially result
        in a new set of quality issues (e.g., <a href=\"https://iphylo.blogspot.com/2019/12/gbif-metagenomics-and-metacrap.html\">GBIF
        metagenomics and metacrap</a>) that take time to resolve. In the case of Plazi,
        I think it would be worthwhile to quantify just how many records have errors,
        and develop benchmarks that we can use to test methods for extracting specimen
        data from text. If we don''t do this then there will remain uncertainty as
        to how much trust we can place in data mined from the taxonomic literature.</p>\n\n<h2>Update</h2>\n\nPlazi
        has responded, see <a href=\"http://plazi.org/posts/2021/10/liberation-first-step-toward-quality/\">Liberating
        material citations as a first step to more better data</a>. My reading of
        their repsonse is that it essentially just reiterates Plazi''s approach and
        doesn''t tackle the underlying issue: their method for extracting material
        citations is error prone, and many of those errors end up in GBIF.","tags":["data
        quality","parsing","Plazi","specimen","text mining"],"language":"en","references":[]},{"id":"https://doi.org/10.59350/j77nc-e8x98","uuid":"c6b101f4-bfbc-4d01-921d-805c43c85757","url":"https://iphylo.blogspot.com/2022/08/linking-taxonomic-names-to-literature.html","title":"Linking
        taxonomic names to the literature","summary":"Just some thoughts as I work
        through some datasets linking taxonomic names to the literature. In the diagram
        above I''ve tried to capture the different situatios I encounter. Much of
        the work I''ve done on this has focussed on case 1 in the diagram: I want
        to link a taxonomic name to an identifier for the work in which that name
        was published. In practise this means linking names to DOIs. This has the
        advantage of linking to a citable indentifier, raising questions such as whether
        citations...","date_published":"2022-08-22T17:19:00Z","date_modified":"2022-08-22T17:19:08Z","date_indexed":"1909-06-16T08:21:41+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"Just some thoughts as I work through
        some datasets linking taxonomic names to the literature.\n\n<div class=\"separator\"
        style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi5ZkbnumEWKZpf0isei_hUJucFlOOK08-SKnJknD8B4qhAX36u-vMQRnZdhRJK5rPb7HNYcnqB7qE4agbeStqyzMkWHrzUj14gPkz2ohmbOVg8P_nHo0hM94PD1wH3SPJsaLAumN8vih3ch9pjH2RaVWZBLwwhGhNu0FS1m5z6j5xt2NeZ4w/s2140/linking%20to%20names144.jpg\"
        style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"\"
        border=\"0\" height=\"600\" data-original-height=\"2140\" data-original-width=\"1604\"
        src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEi5ZkbnumEWKZpf0isei_hUJucFlOOK08-SKnJknD8B4qhAX36u-vMQRnZdhRJK5rPb7HNYcnqB7qE4agbeStqyzMkWHrzUj14gPkz2ohmbOVg8P_nHo0hM94PD1wH3SPJsaLAumN8vih3ch9pjH2RaVWZBLwwhGhNu0FS1m5z6j5xt2NeZ4w/s600/linking%20to%20names144.jpg\"/></a></div>\n\n<p>In
        the diagram above I''ve tried to capture the different situatios I encounter.
        Much of the work I''ve done on this has focussed on case 1 in the diagram:
        I want to link a taxonomic name to an identifier for the work in which that
        name was published. In practise this means linking names to DOIs. This has
        the advantage of linking to a citable indentifier, raising questions such
        as whether citations of taxonmic papers by taxonomic databases could become
        part of a <a href=\"https://iphylo.blogspot.com/2022/08/papers-citing-data-that-cite-papers.html\">taxonomist''s
        Google Scholar profile</a>.</p>\n\n<p>In many taxonomic databases full work-level
        citations are not the norm, instead taxonomists cite one or more pages within
        a work that are relevant to a taxonomic name. These \"microcitations\" (what
        the U.S. legal profession refer to as \"point citations\" or \"pincites\",  see
        <a href=\"https://rasmussen.libanswers.com/faq/283203\">What are pincites,
        pinpoints, or jump legal references?</a>) require some work to map to the
        work itself (which is typically the thing that has a citatble identifier such
        as a DOI).</p>\n\n<p>Microcitations (case 2 in the diagram above) can be quite
        complex. Some might simply mention a single page, but others might list a
        series of (not necessarily contiguous) pages, as well as figures, plates etc.
        Converting these to citable identifiers can be tricky, especially as in most
        cases we don''t have page-level identifiers. The Biodiversity Heritage Library
        (BHL) does have URLs for each scanned page, and we have a standard for referring
        to pages in a PDF (<code>page=&lt;pageNum&gt;</code>, see <a href=\"https://datatracker.ietf.org/doc/html/rfc8118\">RFC
        8118</a>). But how do we refer to a set of pages? Do we pick the first page?
        Do we try and represent a set of pages, and if so, how?</p>\n\n<p>Another
        issue with page-level identifiers is that not everything on a given page may
        be relevant to the taxonomic name. In case 2 above I''ve shaded in the parts
        of the pages and figure that refer to the taxonomic name. An example where
        this can be problematic is the recent test case I created for BHL where a
        page image was included for the taxonomic name <a href=\"https://www.gbif.org/species/195763322\"><i>Aphrophora
        impressa</i></a>. The image includes the species description and a illustration,
        as well as text that relates to other species.</p>\n\n<div class=\"separator\"
        style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg1SAv1XiVBPHXeMLPfdsnTh4Sj4m0AQyqjXM0faXyvbNhBXFDl7SawjFIkMo3qz4RQhDEyZXkKAh5nF4gtfHbVXA6cK3NJ46CuIWECC6HmJKtTjoZ0M3QQXvLY_X-2-RecjBqEy68M0cEr0ph3l6KY51kA9BvGt9d4id314P71PBitpWMATg/s3467/https---www.biodiversitylibrary.org-pageimage-29138463.jpeg\"
        style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"\"
        border=\"0\" height=\"400\" data-original-height=\"3467\" data-original-width=\"2106\"
        src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEg1SAv1XiVBPHXeMLPfdsnTh4Sj4m0AQyqjXM0faXyvbNhBXFDl7SawjFIkMo3qz4RQhDEyZXkKAh5nF4gtfHbVXA6cK3NJ46CuIWECC6HmJKtTjoZ0M3QQXvLY_X-2-RecjBqEy68M0cEr0ph3l6KY51kA9BvGt9d4id314P71PBitpWMATg/s400/https---www.biodiversitylibrary.org-pageimage-29138463.jpeg\"/></a></div>\n\n<p>Given
        that not everything on a page need be relevant, we could extract just the
        relevant blocks of text and illustrations (e.g., paragraphs of text, panels
        within a figure, etc.) and treat that set of elements as the thing to cite.
        This is, of course, what <a href=\"http://plazi.org\">Plazi</a> are doing.
        The set of extracted blocks is glued together as a \"treatment\", assigned
        an identifier (often a DOI), and treated as a citable unit. It would be interesting
        to see to what extent these treatments are actually cited, for example, do
        subsequent revisions that cite work that include treatments cite those treatments,
        or just the work itself? Put another way, are we creating <a href=\"https://iphylo.blogspot.com/2012/09/decoding-nature-encode-ipad-app-omg-it.html\">\"threads\"</a>
        between taxonomic revisions?</p>\n\n<p>One reason for these notes is that
        I''m exploring uploading taxonomic name - literature links to <a href=\"https://www.checklistbank.org\">ChecklistBank</a>
        and case 1 above is easy, as is case 3 (if we have treatment-level identifiers).
        But case 2 is problematic because we are linking to a set of things that may
        not have an identifier, which means a decision has to be made about which
        page to link to, and how to refer to that page.</p>","tags":[],"language":"en","references":[]},{"id":"https://doi.org/10.59350/ymc6x-rx659","uuid":"0807f515-f31d-4e2c-9e6f-78c3a9668b9d","url":"https://iphylo.blogspot.com/2022/09/dna-barcoding-as-intergenerational.html","title":"DNA
        barcoding as intergenerational transfer of taxonomic knowledge","summary":"I
        tweeted about this but want to bookmark it for later as well. The paper “A
        molecular-based identification resource for the arthropods of Finland” doi:10.1111/1755-0998.13510
        contains the following: …the annotated barcode records assembled by FinBOL
        participants represent a tremendous intergenerational transfer of taxonomic
        knowledge … the time contributed by current taxonomists in identifying and
        contributing voucher specimens represents a great gift to future generations
        who will benefit...","date_published":"2022-09-14T10:12:00Z","date_modified":"2022-09-29T13:57:30Z","date_indexed":"1909-06-16T11:02:21+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<p>I <a href=\"https://twitter.com/rdmpage/status/1569738844416638981?s=21&amp;t=9OVXuoUEwZtQt-Ldzlutfw\">tweeted
        about this</a> but want to bookmark it for later as well. The paper “A molecular-based
        identification resource for the arthropods of Finland” <a href=\"https://doi.org/10.1111/1755-0998.13510\">doi:10.1111/1755-0998.13510</a>
        contains the following:</p>\n<blockquote>\n<p>…the annotated barcode records
        assembled by FinBOL participants represent a tremendous <mark>intergenerational
        transfer of taxonomic knowledge</mark> … the time contributed by current taxonomists
        in identifying and contributing voucher specimens represents a great gift
        to future generations who will benefit from their expertise when they are
        no longer able to process new material.</p>\n</blockquote>\n<p>I think this
        is a very clever way to characterise the project. In an age of machine learning
        this may be commonest way to share knowledge , namely as expert-labelled training
        data used to build tools for others. Of course, this means the expertise itself
        may be lost, which has implications for updating the models if the data isn’t
        complete. But it speaks to Charles Godfrey’s theme of  <a href=\"https://biostor.org/reference/250587\">“Taxonomy
        as information science”</a>.</p>\n<p>Note that the knowledge is also transformed
        in the sense that the underlying expertise of interpreting morphology, ecology,
        behaviour, genomics, and the past literature is not what is being passed on.
        Instead it is probabilities that a DNA sequence belongs to a particular taxon.</p>\n<p>This
        feels is different to, say iNaturalist, where there is a machine learning
        model to identify images. In that case, the model is built on something the
        community itself has created, and continues to create. Yes, the underlying
        idea is that same: “experts” have labelled the data, a model is trained, the
        model is used. But the benefits of the <a href=\"https://www.inaturalist.org\">iNaturalist</a>
        model are immediately applicable to the people whose data built the model.
        In the case of barcoding, because the technology itself is still not in the
        hands of many (relative to, say, digital imaging), the benefits are perhaps
        less tangible. Obviously researchers working with environmental DNA will find
        it very useful, but broader impact may await the arrival of citizen science
        DNA barcoding.</p>\n<p>The other consideration is whether the barcoding helps
        taxonomists. Is it to be used to help prioritise future work (“we are getting
        lots of unknown sequences in these taxa, lets do some taxonomy there”), or
        is it simply capturing the knowledge of a generation that won’t be replaced:</p>\n<blockquote>\n<p>The
        need to capture such knowledge is essential because there are, for example,
        no young Finnish taxonomists who can critically identify species in many key
        groups of ar- thropods (e.g., aphids, chewing lice, chalcid wasps, gall midges,
        most mite lineages).</p>\n</blockquote>\n<p>The cycle of collect data, test
        and refine model, collect more data, rinse and repeat that happens with iNaturalist
        creates a feedback loop. It’s not clear that a similar cycle exists for DNA
        barcoding.</p>\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\">StackEdit</a>.</p>\n</blockquote>","tags":[],"language":"en","references":[]},{"id":"https://doi.org/10.59350/d3dc0-7an69","uuid":"545c177f-cea5-4b79-b554-3ccae9c789d7","url":"https://iphylo.blogspot.com/2021/10/reflections-on-macroscope-tool-for-21st.html","title":"Reflections
        on \"The Macroscope\" - a tool for the 21st Century?","summary":"This is a
        guest post by Tony Rees. It would be difficult to encounter a scientist, or
        anyone interested in science, who is not familiar with the microscope, a tool
        for making objects visible that are otherwise too small to be properly seen
        by the unaided eye, or to reveal otherwise invisible fine detail in larger
        objects. A select few with a particular interest in microscopy may also have
        encountered the Wild-Leica \"Macroscope\", a specialised type of benchtop
        microscope optimised for...","date_published":"2021-10-07T12:38:00Z","date_modified":"2021-10-08T10:26:22Z","date_indexed":"1909-06-16T10:02:25+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<p><img src=\"https://lh3.googleusercontent.com/-A99btr6ERMs/Vl1Wvjp2OtI/AAAAAAAAEFI/7bKdRjNG5w0/ytNkVT2U.jpg?imgmax=800\"
        alt=\"YtNkVT2U\" title=\"ytNkVT2U.jpg\" border=\"0\" width=\"128\" height=\"128\"
        style=\"float:right;\" /> This is a guest post by <a href=\"https://about.me/TonyRees\">Tony
        Rees</a>.</p>\n\n<p>It would be difficult to encounter a scientist, or anyone
        interested in science, who is not familiar with the microscope, a tool for
        making objects visible that are otherwise too small to be properly seen by
        the unaided eye, or to reveal otherwise invisible fine detail in larger objects.
        A select few with a particular interest in microscopy may also have encountered
        the Wild-Leica \"Macroscope\", a specialised type of benchtop microscope optimised
        for low-power macro-photography. However in this overview I discuss the \"Macroscope\"
        in a different sense, which is that of the antithesis to the microscope: namely
        a method for visualizing subjects too large to be encompassed by a single
        field of vision, such as the Earth or some subset of its phenomena (the biosphere,
        for example), or conceptually, the universe.</p>\n\n<p><div class=\"separator\"
        style=\"clear: both;\"><a href=\"https://1.bp.blogspot.com/-xXxH9aJn1tY/YV7vnKGQWPI/AAAAAAAAgyQ/7CSJJ663Ry4IXtav54nLcLiI0kda5_L7ACLcBGAsYHQ/s500/2020045672.jpg\"
        style=\"display: block; padding: 1em 0; text-align: center; clear: right;
        float: right;\"><img alt=\"\" border=\"0\" height=\"320\" data-original-height=\"500\"
        data-original-width=\"303\" src=\"https://1.bp.blogspot.com/-xXxH9aJn1tY/YV7vnKGQWPI/AAAAAAAAgyQ/7CSJJ663Ry4IXtav54nLcLiI0kda5_L7ACLcBGAsYHQ/s320/2020045672.jpg\"/></a></div>My
        introduction to the term was via addresses given by Jesse Ausubel in the formative
        years of the 2001-2010 <a href=\"http://www.coml.org\">Census of Marine Life</a>,
        for which he was a key proponent. In Ausubel''s view, the Census would perform
        the function of a macroscope, permitting a view of everything that lives in
        the global ocean (or at least, that subset which could realistically be sampled
        in the time frame available) as opposed to more limited subsets available
        via previous data collection efforts. My view (which could, of course, be
        wrong) was that his thinking had been informed by a work entitled \"Le macroscope,
        vers une vision globale\" published in 1975 by the French thinker Joël de
        Rosnay, who had expressed such a concept as being globally applicable in many
        fields, including the physical and natural worlds but also extending to human
        society, the growth of cities, and more. Yet again, some ecologists may also
        have encountered the term, sometimes in the guise of \"Odum''s macroscope\",
        as an approach for obtaining \"big picture\" analyses of macroecological processes
        suitable for mathematical modelling, typically by elimination of fine detail
        so that only the larger patterns remain, as initially advocated by Howard
        T. Odum in his 1971 book \"Environment, Power, and Society\".</p>\n\n<p>From
        the standpoint of the 21st century, it seems that we are closer to achieving
        a \"macroscope\" (or possibly, multiple such tools) than ever before, based
        on the availability of existing and continuing new data streams, improved
        technology for data assembly and storage, and advanced ways to query and combine
        these large streams of data to produce new visualizations, data products,
        and analytical findings. I devote the remainder of this article to examples
        where either particular workers have employed \"macroscope\" terminology to
        describe their activities, or where potentially equivalent actions are taking
        place without the explicit \"macroscope\" association, but are equally worthy
        of consideration. To save space here, references cited here (most or all)
        can be found via a Wikipedia article entitled \"<a href=\"https://en.wikipedia.org/wiki/Macroscope_(science_concept)\">Macroscope
        (science concept)</a>\" that I authored on the subject around a year ago,
        and have continued to add to on occasion as new thoughts or information come
        to hand (see <a href=\"https://en.wikipedia.org/w/index.php?title=Macroscope_(science_concept)&offset=&limit=500&action=history\">edit
        history for the article</a>).</p>\n\n<p>First, one can ask, what constitutes
        a macroscope, in the present context? In the Wikipedia article I point to
        a book \"Big Data - Related Technologies, Challenges and Future Prospects\"
        by Chen <em>et al.</em> (2014) (<a href=\"https://doi.org/10.1007/978-3-319-06245-7\">doi:10.1007/978-3-319-06245-7</a>),
        in which the \"value chain of big data\" is characterised as divisible into
        four phases, namely data generation, data acquisition (aka data assembly),
        data storage, and data analysis. To my mind, data generation (which others
        may term acquisition, differently from the usage by Chen <em>et al.</em>)
        is obviously the first step, but does not in itself constitute the macroscope,
        except in rare cases - such as Landsat imagery, perhaps - where on its own,
        a single co-ordinated data stream is sufficient to meet the need for a particular
        type of \"global view\". A variant of this might be a coordinated data collection
        program - such as that of the ten year Census of Marine Life - which might
        produce the data required for the desired global view; but again, in reality,
        such data are collected in a series of discrete chunks, in many and often
        disparate data formats, and must be \"wrangled\" into a more coherent whole
        before any meaningful \"macroscope\" functionality becomes available.</p>\n\n<p>Here
        we come to what, in my view, constitutes the heart of the \"macroscope\":
        an intelligently organized (i.e. indexable and searchable), coherent data
        store or repository (where \"data\" may include imagery and other non numeric
        data forms, but much else besides). Taking the Census of Marine Life example,
        the data repository for that project''s data (plus other available sources
        as inputs) is the <a href=\"https://obis.org\">Ocean Biodiversity Information
        System</a> or OBIS (previously the Ocean Biogeographic Information System),
        which according to this view forms the \"macroscope\" for which the Census
        data is a feed. (For non habitat-specific biodiversity data, <a href=\"https://www.gbif.org\">GBIF</a>
        is an equivalent, and more extensive, operation). Other planetary scale \"macroscopes\",
        by this definition (which may or may not have an explicit geographic, i.e.
        spatial, component) would include inventories of biological taxa such as the
        <a href=\"https://www.catalogueoflife.org\">Catalogue of Life</a> and so on,
        all the way back to the pioneering compendia published by Linnaeus in the
        eighteenth century; while for cartography and topographic imagery, the current
        \"blockbuster\" of <a href=\"http://earth.google.com\">Google Earth</a> and
        its predecessors also come well into public consciousness.</p>\n\n<p>In the
        view of some workers and/or operations, both of these phases are precursors
        to the real \"work\" of the macroscope which is to reveal previously unseen
        portions of the \"big picture\" by means either of the availability of large,
        synoptic datasets, or fusion between different data streams to produce novel
        insights. Companies such as IBM and Microsoft have used phraseology such as:</p>\n\n<blockquote>By
        2022 we will use machine-learning algorithms and software to help us organize
        information about the physical world, helping bring the vast and complex data
        gathered by billions of devices within the range of our vision and understanding.
        We call this a \"macroscope\" – but unlike the microscope to see the very
        small, or the telescope that can see far away, it is a system of software
        and algorithms to bring all of Earth''s complex data together to analyze it
        by space and time for meaning.\" (IBM)</blockquote>\n\n<blockquote>As the
        Earth becomes increasingly instrumented with low-cost, high-bandwidth sensors,
        we will gain a better understanding of our environment via a virtual, distributed
        whole-Earth \"macroscope\"... Massive-scale data analytics will enable real-time
        tracking of disease and targeted responses to potential pandemics. Our virtual
        \"macroscope\" can now be used on ourselves, as well as on our planet.\" (Microsoft)
        (references available via the Wikipedia article cited above).</blockquote>\n\n<p>Whether
        or not the analytical capabilities described here are viewed as being an integral
        part of the \"macroscope\" concept, or are maybe an add-on, is ultimately
        a question of semantics and perhaps, personal opinion. Continuing the Census
        of Marine Life/OBIS example, OBIS offers some (arguably rather basic) visualization
        and summary tools, but also makes its data available for download to users
        wishing to analyse it further according to their own particular interests;
        using OBIS data in this manner, Mark Costello et al. in 2017 were able to
        demarcate a finite number of data-supported marine biogeographic realms for
        the first time (Costello et al. 2017: Nature Communications. 8: 1057. <a href=\"https://doi.org/10.1038/s41467-017-01121-2\">doi:10.1038/s41467-017-01121-2</a>),
        a project which I was able to assist in a small way in an advisory capacity.
        In a case such as this, perhaps the final function of the macroscope, namely
        data visualization and analysis, was outsourced to the authors'' own research
        institution. Similarly at an earlier phase, \"data aggregation\" can also
        be virtual rather than actual, i.e. avoiding using a single physical system
        to hold all the data, enabled by open web mapping standards WMS (web map service)
        and WFS (web feature service) to access a set of distributed data stores,
        e.g. as implemented on the portal for the <a href=\"https://portal.aodn.org.au/\">Australian
        Ocean Data Network</a>.</p>\n\n<p>So, as we pass through the third decade
        of the twenty first century, what developments await us in the \"macroscope\"
        area\"? In the biodiversity space, one can reasonably presume that the existing
        \"macroscopic\" data assembly projects such as OBIS and GBIF will continue,
        and hopefully slowly fill current gaps in their coverage - although in the
        marine area, strategic new data collection exercises may be required (Census
        2020, or 2025, anyone?), while (again hopefully), the Catalogue of Life will
        continue its progress towards a \"complete\" species inventory for the biosphere.
        The Landsat project, with imagery dating back to 1972, continues with the
        launch of its latest satellite Landsat 9 just this year (21 September 2021)
        with a planned mission duration for the next 5 years, so the \"macroscope\"
        functionality of that project seems set to continue for the medium term at
        least. Meanwhile the ongoing development of sensor networks, both on land
        and in the ocean, offers an exciting new method of \"instrumenting the earth\"
        to obtain much more real time data than has ever been available in the past,
        offering scope for many more, use case-specific \"macroscopes\" to be constructed
        that can fuse (e.g.) satellite imagery with much more that is happening at
        a local level.</p>\n\n<p>So, the \"macroscope\" concept appears to be alive
        and well, even though the nomenclature can change from time to time (IBM''s
        \"Macroscope\", foreshadowed in 2017, became the \"IBM Pairs Geoscope\" on
        implementation, and is now simply the \"Geospatial Analytics component within
        the IBM Environmental Intelligence Suite\" according to available IBM publicity
        materials). In reality this illustrates a new dichotomy: even if \"everyone\"
        in principle has access to huge quantities of publicly available data, maybe
        only a few well funded entities now have the computational ability to make
        sense of it, and can charge clients a good fee for their services...</p>\n\n<p>I
        present this account partly to give a brief picture of \"macroscope\" concepts
        today and in the past, for those who may be interested, and partly to present
        a few personal views which would be out of scope in a \"neutral point of view\"
        article such as is required on Wikipedia; also to see if readers of this blog
        would like to contribute further to discussion of any of the concepts traversed
        herein.</p>","tags":["guest post","macroscope"],"language":"en","references":[]},{"id":"https://doi.org/10.59350/gf1dw-n1v47","uuid":"a41163e0-9c9a-41e0-a141-f772663f2f32","url":"https://iphylo.blogspot.com/2023/03/dugald-stuart-page-1936-2022.html","title":"Dugald
        Stuart Page 1936-2022","summary":"My dad died last weekend. Below is a notice
        in today''s New Zealand Herald. I''m in New Zealand for his funeral. Don''t
        really have the words for this right now.","date_published":"2023-03-14T03:00:00Z","date_modified":"2023-03-22T07:25:56Z","date_indexed":"1909-06-16T10:41:55+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<div class=\"separator\" style=\"clear:
        both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZweukxntl7R5jnk3knVFVrqZ5RxC7mPZBV4gKeDIglbFzs2O442nbxqs8t8jV2tLqCU24K6gS32jW-Pe8q3O_5JR1Ms3qW1aQAZ877cKkFfcUydqUba9HsgNlX-zS9Ne92eLxRGS8F-lStTecJw2oalp3u58Yoc0oM7CUin5LKPeFIJ7Rzg/s3454/_DSC5106.jpg\"
        style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"\"
        border=\"0\" width=\"400\" data-original-height=\"2582\" data-original-width=\"3454\"
        src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjZweukxntl7R5jnk3knVFVrqZ5RxC7mPZBV4gKeDIglbFzs2O442nbxqs8t8jV2tLqCU24K6gS32jW-Pe8q3O_5JR1Ms3qW1aQAZ877cKkFfcUydqUba9HsgNlX-zS9Ne92eLxRGS8F-lStTecJw2oalp3u58Yoc0oM7CUin5LKPeFIJ7Rzg/s400/_DSC5106.jpg\"/></a></div>\n\nMy
        dad died last weekend. Below is a notice in today''s New Zealand Herald. I''m
        in New Zealand for his funeral. Don''t really have the words for this right
        now.\n\n<div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRUTOFF1VWHCl8dg3FQuaWy5LM7aX8IivdRpTtzgrdQTEymsA5bLTZE3cSQf1WQIP3XrC46JsLScP8BxTK9C5a-B1i51yg8WGSJD0heJVaoDLnerv0lD1o3qloDjqEuuyfX4wagHB5YYBmjWnGeVQvyYVngvDDf9eM6pmMtZ7x94Y4jSVrug/s3640/IMG_2870.jpeg\"
        style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"\"
        border=\"0\" height=\"320\" data-original-height=\"3640\" data-original-width=\"1391\"
        src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRUTOFF1VWHCl8dg3FQuaWy5LM7aX8IivdRpTtzgrdQTEymsA5bLTZE3cSQf1WQIP3XrC46JsLScP8BxTK9C5a-B1i51yg8WGSJD0heJVaoDLnerv0lD1o3qloDjqEuuyfX4wagHB5YYBmjWnGeVQvyYVngvDDf9eM6pmMtZ7x94Y4jSVrug/s320/IMG_2870.jpeg\"/></a></div>","tags":[],"language":"en","references":[]},{"id":"https://doi.org/10.59350/cbzgz-p8428","uuid":"a93134aa-8b33-4dc7-8cd4-76cdf64732f4","url":"https://iphylo.blogspot.com/2023/04/library-interfaces-knowledge-graphs-and.html","title":"Library
        interfaces, knowledge graphs, and Miller columns","summary":"Some quick notes
        on interface ideas for digital libraries and/or knowledge graphs. Recently
        there’s been something of an explosion in bibliographic tools to explore the
        literature. Examples include: Elicit which uses AI to search for and summarise
        papers _scite which uses AI to do sentiment analysis on citations (does paper
        A cite paper B favourably or not?) ResearchRabbit which uses lists, networks,
        and timelines to discover related research Scispace which navigates connections
        between...","date_published":"2023-04-25T13:01:00Z","date_modified":"2023-04-27T14:51:08Z","date_indexed":"1909-06-16T11:25:14+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<p>Some quick notes on interface ideas
        for digital libraries and/or knowledge graphs.</p>\n<p>Recently there’s been
        something of an explosion in bibliographic tools to explore the literature.
        Examples include:</p>\n<ul>\n<li><a href=\"https://elicit.org\">Elicit</a>
        which uses AI to search for and summarise papers</li>\n<li><a href=\"https://scite.ai\">_scite</a>
        which uses AI to do sentiment analysis on citations (does paper A cite paper
        B favourably or not?)</li>\n<li><a href=\"https://www.researchrabbit.ai\">ResearchRabbit</a>
        which uses lists, networks, and timelines to discover related research</li>\n<li><a
        href=\"https://typeset.io\">Scispace</a> which navigates connections between
        papers, authors, topics, etc., and provides AI summaries.</li>\n</ul>\n<p>As
        an aside, I think these (and similar tools) are a great example of how bibliographic
        data such as abstracts, the citation graph and - to a lesser extent - full
        text - have become commodities. That is, what was once proprietary information
        is now free to anyone, which in turns means a whole ecosystem of new tools
        can emerge. If I was clever I’d be building a <a href=\"https://en.wikipedia.org/wiki/Wardley_map\">Wardley
        map</a> to explore this. Note that a decade or so ago reference managers like
        <a href=\"https://www.zotero.org\">Zotero</a> were made possible by publishers
        exposing basic bibliographic data on their articles. As we move to <a href=\"https://i4oc.org\">open
        citations</a> we are seeing the next generation of tools.</p>\n<p>Back to
        my main topic. As usual, rather than focus on what these tools do I’m more
        interested in how they <strong>look</strong>. I have history here, when the
        iPad came out I was intrigued by the possibilities it offered for displaying
        academic articles, as discussed <a href=\"https://iphylo.blogspot.com/2010/08/viewing-scientific-articles-on-ipad.html\">here</a>,
        <a href=\"https://iphylo.blogspot.com/2010/09/viewing-scientific-articles-on-ipad.html\">here</a>,
        <a href=\"https://iphylo.blogspot.com/2010/08/viewing-scientific-articles-on-ipad_24.html\">here</a>,
        <a href=\"https://iphylo.blogspot.com/2010/08/viewing-scientific-articles-on-ipad_3052.html\">here</a>,
        and <a href=\"https://iphylo.blogspot.com/2010/08/viewing-scientific-articles-on-ipad_31.html\">here</a>.
        ResearchRabbit looks like this:</p>\n<div style=\"padding:86.91% 0 0 0;position:relative;\"><iframe
        src=\"https://player.vimeo.com/video/820871442?h=23b05b0dae&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479\"
        frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen
        style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"ResearchRabbit\"></iframe></div><script
        src=\"https://player.vimeo.com/api/player.js\"></script>\n<p>Scispace’s <a
        href=\"https://typeset.io/explore/journals/parassitologia-1ieodjwe\">“trace”
        view</a> looks like this:</p>\n<div style=\"padding:84.55% 0 0 0;position:relative;\"><iframe
        src=\"https://player.vimeo.com/video/820871348?h=2db7b661ef&amp;badge=0&amp;autopause=0&amp;player_id=0&amp;app_id=58479\"
        frameborder=\"0\" allow=\"autoplay; fullscreen; picture-in-picture\" allowfullscreen
        style=\"position:absolute;top:0;left:0;width:100%;height:100%;\" title=\"Scispace
        screencast\"></iframe></div><script src=\"https://player.vimeo.com/api/player.js\"></script>\n<p>What
        is interesting about both is that they display content from left to right
        in vertical columns, rather than the more common horizontal rows. This sort
        of display is sometimes called <a href=\"https://en.wikipedia.org/wiki/Miller_columns\">Miller
        columns</a> or a <a href=\"https://web.archive.org/web/20210726134921/http://designinginterfaces.com/firstedition/index.php?page=Cascading_Lists\">cascading
        list</a>.</p>\n\n<div class=\"separator\" style=\"clear: both;\"><a href=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBPnV9fRBcvm-BX5PjzfG5Cff9PerCLsTW8d5ZbsL6b41t7ypD7ovmcgfTf3b4b34mbq8NM4sfwOHkgEq32FLYnD497RFQD4HQmYmh5Eveu1zWdDVyKyDtPyE98QoxTaOEnLA5kK0fnl3dOOEgUvtVKlTZ8bt1gj2v_8tDRWl9f50ybyei3A/s1024/GNUstep-liveCD.png\"
        style=\"display: block; padding: 1em 0; text-align: center; \"><img alt=\"\"
        border=\"0\" width=\"400\" data-original-height=\"768\" data-original-width=\"1024\"
        src=\"https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEjBPnV9fRBcvm-BX5PjzfG5Cff9PerCLsTW8d5ZbsL6b41t7ypD7ovmcgfTf3b4b34mbq8NM4sfwOHkgEq32FLYnD497RFQD4HQmYmh5Eveu1zWdDVyKyDtPyE98QoxTaOEnLA5kK0fnl3dOOEgUvtVKlTZ8bt1gj2v_8tDRWl9f50ybyei3A/s400/GNUstep-liveCD.png\"/></a></div>\n\n<p>By
        Gürkan Sengün (talk) - Own work, Public Domain, <a href=\"https://commons.wikimedia.org/w/index.php?curid=594715\">https://commons.wikimedia.org/w/index.php?curid=594715</a></p>\n<p>I’ve
        always found displaying a knowledge graph to be a challenge, as discussed
        <a href=\"https://iphylo.blogspot.com/2019/07/notes-on-collections-knowledge-graphs.html\">elsewhere
        on this blog</a> and in my paper on <a href=\"https://peerj.com/articles/6739/#p-29\">Ozymandias</a>.
        Miller columns enable one to drill down in increasing depth, but it doesn’t
        need to be a tree, it can be a path within a network. What I like about ResearchRabbit
        and the original Scispace interface is that they present the current item
        together with a list of possible connections (e.g., authors, citations) that
        you can drill down on. Clicking on these will result in a new column being
        appended to the right, with a view (typically a list) of the next candidates
        to visit. In graph terms, these are adjacent nodes to the original item.  The
        clickable badges on each item can be thought of as sets of edges that have
        the same label (e.g., “authored by”, “cites”, “funded”, “is about”, etc.).
        Each of these nodes itself becomes a starting point for further exploration.
        Note that the original starting point isn’t privileged, other than being the
        starting point. That is, each time we drill down we are seeing the same type
        of information displayed in the same way. Note also that the navigation can
        be though of as a <strong>card</strong> for a node, with <strong>buttons</strong>
        grouping the adjacent nodes. When we click on an individual button, it expands
        into a <strong>list</strong> in the next column. This can be thought of as
        a preview for each adjacent node. Clicking on an element in the list generates
        a new card (we are viewing a single node) and we get another set of buttons
        corresponding to the adjacent nodes.</p>\n<p>One important behaviour in a
        Miller column interface is that the current path can be pruned at any point.
        If we go back (i.e., scroll to the left) and click on another tab on an item,
        everything downstream of that item (i.e., to the right) gets deleted and replaced
        by a new set of nodes. This could make retrieving a particular history of
        browsing a bit tricky, but encourages exploration. Both Scispace and ResearchRabbit  have
        the ability to add items to a collection, so you can keep track of things
        you discover.</p>\n<p>Lots of food for thought, I’m assuming that there is
        some user interface/experience research on Miller columns. One thing to remember
        is that Miller columns are most often associated with trees, but in this case
        we are exploring a network. That means that potentially there is no limit
        to the number of columns being generated as we wander through the graph. It
        will be interesting to think about what the average depth is likely to be,
        in other words, how deep down the rabbit hole will be go?</p>\n\n<h3>Update</h3>\n<p>Should
        add link to David Regev''s explorations of <a href=\"https://medium.com/david-regev-on-ux/flow-browser-b730daf0f717\">Flow
        Browser</a>.\n\n<blockquote>\n<p>Written with <a href=\"https://stackedit.io/\">StackEdit</a>.</p>\n</blockquote>","tags":["cards","flow","Knowledge
        Graph","Miller column","RabbitResearch"],"language":"en","references":[]},{"id":"https://doi.org/10.59350/t6fb9-4fn44","uuid":"8bc3fea6-cb86-4344-8dad-f312fbf58041","url":"https://iphylo.blogspot.com/2021/12/the-business-of-extracting-knowledge.html","title":"The
        Business of Extracting Knowledge from Academic Publications","summary":"Markus
        Strasser (@mkstra write a fascinating article entitled \"The Business of Extracting
        Knowledge from Academic Publications\". I spent months working on domain-specific
        search engines and knowledge discovery apps for biomedicine and eventually
        figured that synthesizing \"insights\" or building knowledge graphs by machine-reading
        the academic literature (papers) is *barely useful* :https://t.co/eciOg30Odc—
        Markus Strasser (@mkstra) December 7, 2021 His TL;DR: TL;DR: I worked on biomedical...","date_published":"2021-12-11T00:01:00Z","date_modified":"2021-12-11T00:01:21Z","date_indexed":"1909-06-16T11:32:09+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<p>Markus Strasser (<a href=\"https://twitter.com/mkstra\">@mkstra</a>
        write a fascinating article entitled <a href=\"https://markusstrasser.org/extracting-knowledge-from-literature/\">\"The
        Business of Extracting Knowledge from Academic Publications\"</a>.</p>\n\n<blockquote
        class=\"twitter-tweet\"><p lang=\"en\" dir=\"ltr\">I spent months working
        on domain-specific search engines and knowledge discovery apps for biomedicine
        and eventually figured that synthesizing &quot;insights&quot; or building
        knowledge graphs by machine-reading the academic literature (papers) is *barely
        useful* :<a href=\"https://t.co/eciOg30Odc\">https://t.co/eciOg30Odc</a></p>&mdash;
        Markus Strasser (@mkstra) <a href=\"https://twitter.com/mkstra/status/1468334482113523716?ref_src=twsrc%5Etfw\">December
        7, 2021</a></blockquote> <script async src=\"https://platform.twitter.com/widgets.js\"
        charset=\"utf-8\"></script>\n\n<p>His TL;DR:</p>\n\n<p><blockquote>\nTL;DR:
        I worked on biomedical literature search, discovery and recommender web applications
        for many months and concluded that extracting, structuring or synthesizing
        \"insights\" from academic publications (papers) or building knowledge bases
        from a domain corpus of literature has negligible value in industry.</p>\n\n<p>Close
        to nothing of what makes science actually work is published as text on the
        web.\n</blockquote></p>\n\n<p>After recounting the many problems of knowledge
        extraction - including a swipe at nanopubs which \"are ... dead in my view
        (without admitting it)\" - he concludes:</p>\n\n<p><blockquote>\nI’ve been
        flirting with this entire cluster of ideas including open source web annotation,
        semantic search and semantic web, public knowledge graphs, nano-publications,
        knowledge maps, interoperable protocols and structured data, serendipitous
        discovery apps, knowledge organization, communal sense making and academic
        literature/publishing toolchains for a few years on and off ... nothing of
        it will go anywhere.</p>\n\n<p>Don’t take that as a challenge. Take it as
        a red flag and run. Run towards better problems.\n</blockquote></p>\n\n<p>Well
        worth a read, and much food for thought.</p>","tags":["ai","business model","text
        mining"],"language":"en","references":[]},{"id":"https://doi.org/10.59350/463yw-pbj26","uuid":"dc829ab3-f0f1-40a4-b16d-a36dc0e34166","url":"https://iphylo.blogspot.com/2022/12/david-remsen.html","title":"David
        Remsen","summary":"I heard yesterday from Martin Kalfatovic (BHL) that David
        Remsen has died. Very sad news. It''s starting to feel like iPhylo might end
        up being a list of obituaries of people working on biodiversity informatics
        (e.g., Scott Federhen). I spent several happy visits at MBL at Woods Hole
        talking to Dave at the height of the uBio project, which really kickstarted
        large scale indexing of taxonomic names, and the use of taxonomic name finding
        tools to index the literature. His work on uBio with David...","date_published":"2022-12-16T17:54:00Z","date_modified":"2022-12-17T08:12:23Z","date_indexed":"1909-06-16T11:41:39+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<p>I heard yesterday from Martin Kalfatovic
        (BHL) that David Remsen has died. Very sad news. It''s starting to feel like
        iPhylo might end up being a list of obituaries of people working on biodiversity
        informatics (e.g., <a href=\"https://iphylo.blogspot.com/2016/05/scott-federhen-rip.html\">Scott
        Federhen</a>).</p>\n\n<p>I spent several happy visits at MBL at Woods Hole
        talking to Dave at the height of the uBio project, which really kickstarted
        large scale indexing of taxonomic names, and the use of taxonomic name finding
        tools to index the literature. His work on uBio with David (\"Paddy\") Patterson
        led to the <a href=\"https://eol.org\">Encyclopedia of Life</a> (EOL).</p>\n\n<p>A
        number of the things I''m currently working on are things Dave started. For
        example, I recently uploaded a version of his dataset for Nomenclator Zoologicus[1]
        to <a href=\"https://www.checklistbank.org/dataset/126539/about\">ChecklistBank</a>
        where I''m working on augmenting that original dataset by adding links to
        the taxonomic literature. My <a href=\"https://biorss.herokuapp.com/?feed=Y291bnRyeT1XT1JMRCZwYXRoPSU1QiUyMkJJT1RBJTIyJTVE\">BioRSS
        project</a> is essentially an attempt to revive uBioRSS[2] (see <a href=\"https://iphylo.blogspot.com/2021/11/revisiting-rss-to-monitor-latests.html\">Revisiting
        RSS to monitor the latest taxonomic research</a>).</p>\n\n<p>I have fond memories
        of those visits to Woods Hole. A very sad day indeed.</p>\n\n<p><b>Update:</b>
        The David Remsen Memorial Fund has been set up on <a href=\"https://www.gofundme.com/f/david-remsen-memorial-fund\">GoFundMe</a>.</p>\n\n<p>1.
        Remsen, D. P., Norton, C., & Patterson, D. J. (2006). Taxonomic Informatics
        Tools for the Electronic Nomenclator Zoologicus. The Biological Bulletin,
        210(1), 18–24. https://doi.org/10.2307/4134533</p>\n\n<p>2. Patrick R. Leary,
        David P. Remsen, Catherine N. Norton, David J. Patterson, Indra Neil Sarkar,
        uBioRSS: Tracking taxonomic literature using RSS, Bioinformatics, Volume 23,
        Issue 11, June 2007, Pages 1434–1436, https://doi.org/10.1093/bioinformatics/btm109</p>","tags":["David
        Remsen","obituary","uBio"],"language":"en","references":[]},{"id":"https://doi.org/10.59350/3s376-6bm21","uuid":"62e7b438-67a3-44ac-a66d-3f5c278c949e","url":"https://iphylo.blogspot.com/2022/02/deduplicating-bibliographic-data.html","title":"Deduplicating
        bibliographic data","summary":"There are several instances where I have a
        collection of references that I want to deduplicate and merge. For example,
        in Zootaxa has no impact factor I describe a dataset of the literature cited
        by articles in the journal Zootaxa. This data is available on Figshare (https://doi.org/10.6084/m9.figshare.c.5054372.v4),
        as is the equivalent dataset for Phytotaxa (https://doi.org/10.6084/m9.figshare.c.5525901.v1).
        Given that the same articles may be cited many times, these datasets have
        lots of...","date_published":"2022-02-03T15:09:00Z","date_modified":"2022-02-03T15:11:29Z","date_indexed":"1909-06-16T10:22:30+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<p>There are several instances where
        I have a collection of references that I want to deduplicate and merge. For
        example, in <a href=\"https://iphylo.blogspot.com/2020/07/zootaxa-has-no-impact-factor.html\">Zootaxa
        has no impact factor</a> I describe a dataset of the literature cited by articles
        in the journal <i>Zootaxa</i>. This data is available on Figshare (<a href=\"https://doi.org/10.6084/m9.figshare.c.5054372.v4\">https://doi.org/10.6084/m9.figshare.c.5054372.v4</a>),
        as is the equivalent dataset for <i>Phytotaxa</i> (<a href=\"https://doi.org/10.6084/m9.figshare.c.5525901.v1\">https://doi.org/10.6084/m9.figshare.c.5525901.v1</a>).
        Given that the same articles may be cited many times, these datasets have
        lots of duplicates. Similarly, articles in <a href=\"https://species.wikimedia.org\">Wikispecies</a>
        often have extensive lists of references cited, and the same reference may
        appear on multiple pages (for an initial attempt to extract these references
        see <a href=\"https://doi.org/10.5281/zenodo.5801661\">https://doi.org/10.5281/zenodo.5801661</a>
        and <a href=\"https://github.com/rdmpage/wikispecies-parser\">https://github.com/rdmpage/wikispecies-parser</a>).</p>\n\n<p>There
        are several reasons I want to merge these references. If I want to build a
        citation graph for <i>Zootaxa</i> or <i>Phytotaxa</i> I need to merge references
        that are the same so that I can accurate count citations. I am also interested
        in harvesting the metadata to help find those articles in the <a href=\"https://www.biodiversitylibrary.org\">Biodiversity
        Heritage Library</a> (BHL), and the literature cited section of scientific
        articles is a potential goldmine of bibliographic metadata, as is Wikispecies.</p>\n\n<p>After
        various experiments and false starts I''ve created a repository <a href=\"https://github.com/rdmpage/bib-dedup\">https://github.com/rdmpage/bib-dedup</a>
        to host a series of PHP scripts to deduplicate bibliographics data. I''ve
        settled on using CSL-JSON as the format for bibliographic data. Because deduplication
        relies on comparing pairs of references, the standard format for most of the
        scripts is a JSON array containing a pair of CSL-JSON objects to compare.
        Below are the steps the code takes.</p>\n\n<h2>Generating pairs to compare</h2>\n\n<p>The
        first step is to take a list of references and generate the pairs that will
        be compared. I started with this approach as I wanted to explore machine learning
        and wanted a simple format for training data, such as an array of two CSL-JSON
        objects and an integer flag representing whether the two references were the
        same of different.</p>\n\n<p>There are various ways to generate CSL-JSON for
        a reference. I use a tool I wrote (see <a href=\"https://iphylo.blogspot.com/2021/07/citation-parsing-released.html\">Citation
        parsing tool released</a>) that has a simple API where you parse one or more
        references and it returns that reference as structured data in CSL-JSON.</p>\n\n<p>Attempting
        to do all possible pairwise comparisons rapidly gets impractical as the number
        of references increases, so we need some way to restrict the number of comparisons
        we make. One approach I''ve explored is the “sorted neighbourhood method”
        where we sort the references 9for example by their title) then move a sliding
        window down the list of references, comparing all references within that window.
        This greatly reduces the number of pairwise comparisons. So the first step
        is to sort the references, then run a sliding window over them, output all
        the pairs in each window (ignoring in pairwise comparisons already made in
        a previous window). Other methods of \"blocking\" could also be used, such
        as only including references in a particular year, or a particular journal.</p>\n\n<p>So,
        the output of this step is a set of JSON arrays, each with a pair of references
        in CSL-JSON format. Each array is stored on a single line in the same file
        in <a href=\"https://en.wikipedia.org/wiki/JSON_streaming#Line-delimited_JSON_2\">line-delimited
        JSON</a> (JSONL).</p>\n\n<h2>Comparing pairs</h2>\n\n<p>The next step is to
        compare each pair of references and decide whether they are a match or not.
        Initially I explored a machine learning approach used in the following paper:</p>\n\n<blockquote>\nWilson
        DR. 2011. Beyond probabilistic record linkage: Using neural networks and complex
        features to improve genealogical record linkage. In: The 2011 International
        Joint Conference on Neural Networks. 9–14. DOI: <a href=\"https://doi.org/10.1109/IJCNN.2011.6033192\">10.1109/IJCNN.2011.6033192</a>\n</blockquote>\n\n<p>Initial
        experiments using <a href=\"https://github.com/jtet/Perceptron\">https://github.com/jtet/Perceptron</a>
        were promising and I want to play with this further, but I deciding to skip
        this for now and just use simple string comparison. So for each CSL-JSON object
        I generate a citation string in the same format using CiteProc, then compute
        the <a href=\"https://en.wikipedia.org/wiki/Levenshtein_distance\">Levenshtein
        distance</a> between the two strings. By normalising this distance by the
        length of the two strings being compared I can use an arbitrary threshold
        to decide if the references are the same or not.</p>\n\n<h2>Clustering</h2>\n\n<p>For
        this step we read the JSONL file produced above and record whether the two
        references are a match or not. Assuming each reference has a unique identifier
        (needs only be unique within the file) then we can use those identifier to
        record the clusters each reference belongs to. I do this using a <a href=\"https://en.wikipedia.org/wiki/Disjoint-set_data_structure\">Disjoint-set
        data structure</a>. For each reference start with a graph where each node
        represents a reference, and each node has a pointer to a parent node. Initially
        the reference is its own parent. A simple implementation is to have an array
        index by reference identifiers and where the value of each cell in the array
        is the node''s parent.</p>\n\n<p>As we discover pairs we update the parents
        of the nodes to reflect this, such that once all the comparisons are done
        we have a one or more sets of clusters corresponding to the references that
        we think are the same. Another way to think of this is that we are getting
        the components of a graph where each node is a reference and pair of references
        that match are connected by an edge.</p>\n\n<p>In the code I''m using I write
        this graph in <a href=\"https://en.wikipedia.org/wiki/Trivial_Graph_Format\">Trivial
        Graph Format</a> (TGF) which can be visualised using a tools such as <a href=\"https://www.yworks.com/products/yed\">yEd</a>.</p>\n\n<h2>Merging</h2>\n\n<p>Now
        that we have a graph representing the sets of references that we think are
        the same we need to merge them. This is where things get interesting as the
        references are similar (by definition) but may differ in some details. The
        paper below describes a simple Bayesian approach for merging records:</p>\n\n<blockquote>\nCouncill
        IG, Li H, Zhuang Z, Debnath S, Bolelli L, Lee WC, Sivasubramaniam A, Giles
        CL. 2006. Learning Metadata from the Evidence in an On-line Citation Matching
        Scheme. In: Proceedings of the 6th ACM/IEEE-CS Joint Conference on Digital
        Libraries. JCDL ’06. New York, NY, USA: ACM, 276–285. DOI: <a href=\"https://doi.org/10.1145/1141753.1141817\">10.1145/1141753.1141817</a>.\n</blockquote>\n\n<p>So
        the next step is to read the graph with the clusters, generate the sets of
        bibliographic references that correspond to each cluster, then use the method
        described in Councill et al. to produce a single bibliographic record for
        that cluster. These records could then be used to, say locate the corresponding
        article in BHL, or populate Wikidata with missing references.</p>\n\n<p>Obviously
        there is always the potential for errors, such as trying to merge references
        that are not the same. As a quick and dirty check I flag as dubious any cluster
        where the page numbers vary among members of the cluster. More sophisticated
        checks are possible, especially if I go down the ML route (i.e., I would have
        evidence for the probability that the same reference can disagree on some
        aspects of metadata).</p>\n\n<h2>Summary</h2>\n\n<p>At this stage the code
        is working well enough for me to play with and explore some example datasets.
        The focus is on structured bibliographic metadata, but I may simplify things
        and have a version that handles simple string matching, for example to cluster
        together different abbreviations of the same journal name.</p>","tags":["data
        cleaning","deduplication","Phytotaxa","Wikispecies","Zootaxa"],"language":"en","references":[]},{"id":"https://doi.org/10.59350/c79vq-7rr11","uuid":"3cb94422-5506-4e24-a41c-a250bb521ee0","url":"https://iphylo.blogspot.com/2021/12/graphql-for-wikidata-wikicite.html","title":"GraphQL
        for WikiData (WikiCite)","summary":"I''ve released a very crude GraphQL endpoint
        for WikiData. More precisely, the endpoint is for a subset of the entities
        that are of interest to WikiCite, such as scholarly articles, people, and
        journals. There is a crude demo at https://wikicite-graphql.herokuapp.com.
        The endpoint itself is at https://wikicite-graphql.herokuapp.com/gql.php.
        There are various ways to interact with the endpoint, personally I like the
        Altair GraphQL Client by Samuel Imolorhe. As I''ve mentioned earlier it''s
        taken...","date_published":"2021-12-20T13:16:00Z","date_modified":"2021-12-20T13:20:05Z","date_indexed":"1909-06-16T10:52:00+00:00","authors":[{"url":null,"name":"Roderic
        Page"}],"image":null,"content_html":"<div class=\"separator\" style=\"clear:
        both;\"><a href=\"https://blogger.googleusercontent.com/img/a/AVvXsEh7WW8TlfN2u3xe_E-sH5IK6AWYnAoWaKrP2b32UawUeqMpPlq6ZFk5BtJVZsMmCNh5j3QRsTj5H0Ee55RRGntnc9yjj_mNB8KHmH2dzocCgyLS2VFOxsBji6u4Ey6qxlDAnT-zrsBpnDcTchbhgt1x0Sf7RkmIMkS1y4-_3KCQian-SeIF-g=s1000\"
        style=\"display: block; padding: 1em 0; text-align: center; clear: right;
        float: right;\"><img alt=\"\" border=\"0\" width=\"128\" data-original-height=\"1000\"
        data-original-width=\"1000\" src=\"https://blogger.googleusercontent.com/img/a/AVvXsEh7WW8TlfN2u3xe_E-sH5IK6AWYnAoWaKrP2b32UawUeqMpPlq6ZFk5BtJVZsMmCNh5j3QRsTj5H0Ee55RRGntnc9yjj_mNB8KHmH2dzocCgyLS2VFOxsBji6u4Ey6qxlDAnT-zrsBpnDcTchbhgt1x0Sf7RkmIMkS1y4-_3KCQian-SeIF-g=s200\"/></a></div><p>I''ve
        released a very crude GraphQL endpoint for WikiData. More precisely, the endpoint
        is for a subset of the entities that are of interest to WikiCite, such as
        scholarly articles, people, and journals. There is a crude demo at <a href=\"https://wikicite-graphql.herokuapp.com\">https://wikicite-graphql.herokuapp.com</a>.
        The endpoint itself is at <a href=\"https://wikicite-graphql.herokuapp.com/gql.php\">https://wikicite-graphql.herokuapp.com/gql.php</a>.
        There are various ways to interact with the endpoint, personally I like the
        <a href=\"https://altair.sirmuel.design\">Altair GraphQL Client</a> by <a
        href=\"https://github.com/imolorhe\">Samuel Imolorhe</a>.</p>\n\n<p>As I''ve
        <a href=\"https://iphylo.blogspot.com/2021/04/it-been-while.html\">mentioned
        earlier</a> it''s taken me a while to see the point of GraphQL. But it is
        clear it is gaining traction in the biodiversity world (see for example the
        <a href=\"https://dev.gbif.org/hosted-portals.html\">GBIF Hosted Portals</a>)
        so it''s worth exploring. My take on GraphQL is that it is a way to create
        a self-describing API that someone developing a web site can use without them
        having to bury themselves in the gory details of how data is internally modelled.
        For example, WikiData''s query interface uses SPARQL, a powerful language
        that has a steep learning curve (in part because of the administrative overhead
        brought by RDF namespaces, etc.). In my previous SPARQL-based projects such
        as <a href=\"https://ozymandias-demo.herokuapp.com\">Ozymandias</a> and <a
        href=\"http://alec-demo.herokuapp.com\">ALEC</a> I have either returned SPARQL
        results directly (Ozymandias) or formatted SPARQL results as <a href=\"https://schema.org/DataFeed\">schema.org
        DataFeeds</a> (equivalent to RSS feeds) (ALEC). Both approaches work, but
        they are project-specific and if anyone else tried to build based on these
        projects they might struggle for figure out what was going on. I certainly
        struggle, and I wrote them!</p>\n\n<p>So it seems worthwhile to explore this
        approach a little further and see if I can develop a GraphQL interface that
        can be used to build the sort of rich apps that I want to see. The demo I''ve
        created uses SPARQL under the hood to provide responses to the GraphQL queries.
        So in this sense it''s not replacing SPARQL, it''s simply providing a (hopefully)
        simpler overlay on top of SPARQL so that we can retrieve the data we want
        without having to learn the intricacies of SPARQL, nor how Wikidata models
        publications and people.</p>","tags":["GraphQL","SPARQL","WikiCite","Wikidata"],"language":"en","references":[]}]}'
  recorded_at: Sun, 18 Jun 2023 06:01:20 GMT
recorded_with: VCR 6.1.0
